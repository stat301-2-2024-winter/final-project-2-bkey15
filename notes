## 02/21/24 ##

- I think I can merge tidymodels fits with mice package, specifically as.mira()? See https://amices.org/mice/reference/as.mira.html

- Description of process:
  1. PREDICT hr_score through a standard tidymodeling process. This will include the use of step_impute_bag to impute predictors.
  2. SUBSTITUTE missing values in hr_score with predictions, assuming model is found to be robust.
  3. FIT a model (with hr_score as outcome, now that it's complete) using the tidymodeling process, again imputing predictors with step_impute_bag.
  4. REPEAT to create a series of fits (perhaps m=5) suitable for the mice package.
  5. TRANSFORM fits with as.mira so that they're ready to...
  6. POOL, yielding the final inference.
  
- **Step 1 is what this project endeavors to complete.**
- Step 3 will need the use v-fold cross-validation to locate the optimal tuning parameters, given that I'll be relying on a lasso regression at this point.
- I'm having issues with proof of concept for Step 5, but I'm assuming it'll be doable.
- Another way to begin step 3 is to convert imputed datasets (created tidymodeling preprocessing, ending specifically with prep + bake) into mids objects using as.mids, and then running the fit using: with(mids_obj, formula). Formula would need to use glmnet for lasso. Does look hard to convert objects into mids_obj, though...
- The main question I'm thinking through is: should I merge 5-ish fits, or 5-ish imputed datasets, either of which could fully rely on tidymodeling?
- Or I could just do the whole thing beginning with Step 3 using mice. Might be easier, might not be...

## 02/22/24 ##

- For this project, I should run two predictions: one for avg_kill_tort as the sole predictor, and the other using a bigger (but not too big) set of variables.
- I tried imputing all missing values in the dataset last night to no avail (R aborted task due to max-out of memory).
- I've tried merging PTS & QoG (which has PTS) with preproc_data, but it's not completing correctly due to missingness in cowcode.
- Only observations with a cowcode has a corresponding hr_score. That is, there is no hr_score for any observation that lacks a cowcode.
- These are the cases lacking a cowcode + hr_score in preproc_data:
  - Palestine/West Bank
  - Palestine/Gaza
  - Somaliland
  - Hong Kong
  - Palestine/British Mandate
  - Zanzibar
- Pretty similar set of cases (cow_year duplicates) in pts.
- This is an extremely limited number of cases that probably don't matter for the issue of trade agreements. Going to filter these out to get a consistent merge.
- I suppose I could create a step_dummy using country_name_vdem rather than cowcode?
- This actually wouldn't work since there's no data at all to fit and test performance. What could potentially work is estimating by introducing a step_dummy for region rather than country. Maybe return to this, especially if dummy by country is too computationally difficult.
- Also, step_dummy for time (year) isn't going to work either. Computing the estimated relationship between 2015, 2016, etc. and the outcome doesn't give us any information as to what the relationship will be in 2020, 2021, etc. So, let's leave out the time component. Also, it can be argued from a theoretical standpoint that the relationship between political killings, etc. and human rights performance is unaffected by time considerations (i.e., if a government kills, then it's ipso facto performing poorly HR-wise, irrespective of the time point).

## 02/24/24 ##

- After merging, there's a lot of missingness for the Czech Republic. V-Dem calls it "Czechia," even during the Czechoslovakia period, so it's safe to replace these values with that of Czechoslovakia's. May need to do this early on in the preprocessing.
- Am ultimately going to change Czechoslovakia's COW code from 315 to 316 (Czechia's). Both the V-Dem and HR Scores datasets treat the latter as a continuation of the former, hence why I'm not gonig to separate the two entirely by recoding pre-1993 Czechia's years to 315 in my preprocessed dataset.
- The microstates don't appear in the V-Dem dataset at all. Will be removing these observations wholesale.
- Extant but marginal missingness for post-Soviet states, DDR, West Germany, etc., due to coding gaps, late coding start dates, etc. Will just remove these observations.
- Important: we need to set seed for knn fits, because R will randomly break ties between observations if a tie exists.
- Deleted "memos" folder because it's messing up how plots are read in to the qmds

## 02/25/24 ##

- Might have a multicollinearity issue with avg_kill_tort and v2x_clphy. Run the models again after removing the latter?

## 02/29/24 ##

- I've explored recipes that remove the variables at issue re: multicollinearity. They don't improve model performance. Research shows that multicollinearity probably isn't a huge issue for prediction (see that time series textbook I alwaus use).
- For the final write-up, be sure to discuss the removal of cases where cowcode = 0 (even if we assigned these cases arbitrary cow codes such that they would be included in the cowcode predictor dummy, they don't appear in hr_scores, so there's no way to predict a relationship).
- Thinking about whether lagging hr_scores would be interesting to test. Not sure, honestly. Maybe just test it on the baselines for now.

## 03/02/24 ##

- cow_code 345 is Yugoslavia in cow_codes and hr_scores, but Serbia in vdem.

## 03/03/24 ##

- In step_normalize, each value (z_{i}) is calculated by the formula: (x_{i} - xbar)/s
- I have stored xbar and s for log10_e_* pop, gdp, and gdppc in the post-assessment preprocessing phase. See that script. Will use this formula to de-normalize predictions.
- Specifically, we can solve for the original value (x_{i}) by: z*s + xbar
- Only 4 values for these variables are being imputed using prep-bake w/ KNN imputation (3 Bhutan + 1 diff case); note this as to why it's probably unnecessary to conduct further sets of imputations.

## 03/07/24 ##

-For new "most-averse" feature-engineering recipes, I've removed:
  1. The high-level indices, as these are all comprised of the mid-level indices.
  2. avg_kill_tort & v2x_egal, because they're simple averages of other indicators. (Some of the other mid-level indices are averages, but they're weighted or contain other rules that render them "complex.")
  3. v2x_suffr & log10_e_gdp, because both have low-correlations with hr_score. (The former is a measure of de jure, not de facto, suffrage; the latter is perhaps only related to hr_score through population, which is negatively correlated with hr_score since the world's largest countries happen to have low HR scores.)
